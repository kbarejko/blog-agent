# AI Provider Configuration
# Configure AI providers for article generation

providers:
  # Claude (Anthropic) - Primary provider
  claude:
    api_key: ${ANTHROPIC_API_KEY}  # Set via environment variable
    model: claude-sonnet-4-20250514
    max_tokens: 4000
    temperature: 1.0

  # OpenAI
  openai:
    api_key: ${OPENAI_API_KEY}  # Set via environment variable
    model: gpt-4-turbo
    max_tokens: 4000
    temperature: 0.7

  # OpenAI - GPT-4o (latest)
  openai-gpt4o:
    api_key: ${OPENAI_API_KEY}
    model: gpt-4o
    max_tokens: 4000
    temperature: 0.7

  # OpenAI - GPT-3.5 Turbo (cheaper)
  openai-gpt35:
    api_key: ${OPENAI_API_KEY}
    model: gpt-3.5-turbo
    max_tokens: 4000
    temperature: 0.7

  # Ollama - Local models
  ollama:
    model: llama3:latest  # Change to any installed model (llama3, mistral, codellama, etc.)
    host: http://192.168.0.136:11434  # Ollama server URL (Windows host)
    max_tokens: 4000
    temperature: 0.7

  # Ollama - Mistral variant
  ollama-mistral:
    model: mistral:latest
    host: http://192.168.0.136:11434
    max_tokens: 4000
    temperature: 0.7

  # Ollama - CodeLlama variant
  ollama-codellama:
    model: codellama:13b
    host: http://192.168.0.136:11434
    max_tokens: 4000
    temperature: 0.7

# Default provider
default: claude
